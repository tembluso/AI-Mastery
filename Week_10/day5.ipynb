{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca8bdeea",
   "metadata": {},
   "source": [
    "Week 10 ¬∑ Day 5 ‚Äî Explainability (Saliency / Grad-CAM for Text)\n",
    "Why this matters\n",
    "\n",
    "Deep models are black boxes. For NLP, we want to see which words influenced the prediction most. Saliency maps highlight tokens by measuring gradients ‚Äî helping debug models and build trust.\n",
    "\n",
    "Theory Essentials\n",
    "\n",
    "Saliency = ‚àÇoutput/‚àÇembedding: gradient shows sensitivity to tokens.\n",
    "\n",
    "High magnitude = token strongly affects prediction.\n",
    "\n",
    "Works like Grad-CAM in vision but on word embeddings.\n",
    "\n",
    "Can overlay scores as heatmaps on text.\n",
    "\n",
    "Helps catch dataset bias (e.g., model relying on single words like ‚Äú!‚Äù)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9699cc9e",
   "metadata": {},
   "source": [
    "üîπ What embeddings are\n",
    "\n",
    "Embeddings are vectors that represent tokens (words, subwords, characters) in a continuous space.\n",
    "\n",
    "Instead of representing a word as a one-hot vector (huge and sparse), we learn a dense vector of fixed size (e.g., 100-dim or 300-dim).\n",
    "\n",
    "The idea: words with similar meaning or usage end up close together in this vector space.\n",
    "\n",
    "üëâ Example:\n",
    "king ‚âà queen but offset by gender direction,\n",
    "walk ‚âà run, closer than to banana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56cacc40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: [4, 7, 8, 9, 0]\n",
      "Saliency scores: [0.02306676 0.01659771 0.01332968 0.01369807 0.        ]\n"
     ]
    }
   ],
   "source": [
    "import torch, torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Simple BiLSTM classifier\n",
    "class BiLSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size=100, embed_dim=16, hidden_dim=32, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_dim*2, num_classes)\n",
    "    def forward(self, x, lengths):\n",
    "        embeds = self.embedding(x)\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(embeds, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        _, (h_n, _) = self.lstm(packed)\n",
    "        h_cat = torch.cat((h_n[-2], h_n[-1]), dim=1)\n",
    "        return self.fc(h_cat), embeds\n",
    "\n",
    "# Fake example\n",
    "vocab_size = 100\n",
    "tokens = torch.tensor([[4, 7, 8, 9, 0]])  # padded sentence\n",
    "lengths = torch.tensor([4])\n",
    "label = torch.tensor([1])\n",
    "\n",
    "model = BiLSTMClassifier(vocab_size=vocab_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Forward pass\n",
    "logits, embeds = model(tokens, lengths)\n",
    "loss = criterion(logits, label)\n",
    "\n",
    "# Backprop to get gradients wrt embeddings\n",
    "loss.backward()\n",
    "saliency = tokens.detach().clone().float()\n",
    "\n",
    "# grads: [batch, seq, embed_dim]\n",
    "grads = model.embedding.weight.grad\n",
    "token_grads = grads[tokens[0]]   # [seq, embed_dim]\n",
    "\n",
    "# Magnitude per token\n",
    "saliency_scores = token_grads.norm(dim=1).detach().numpy()\n",
    "\n",
    "print(\"Tokens:\", tokens[0].tolist())\n",
    "print(\"Saliency scores:\", saliency_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d0da3f",
   "metadata": {},
   "source": [
    "1) Core (10‚Äì15 min)\n",
    "\n",
    "Task: Print the most influential token (highest saliency score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fea87d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most influential token: 4\n"
     ]
    }
   ],
   "source": [
    "print(\"Most influential token:\", tokens[0][np.argmax(saliency_scores)].item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d78d3ad",
   "metadata": {},
   "source": [
    "2) Practice (10‚Äì15 min)\n",
    "\n",
    "Task: Normalize saliency scores (0‚Äì1) and print them alongside tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46ed27e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token 4 ‚Üí 1.00\n",
      "Token 7 ‚Üí 0.72\n",
      "Token 8 ‚Üí 0.58\n",
      "Token 9 ‚Üí 0.59\n",
      "Token 0 ‚Üí 0.00\n"
     ]
    }
   ],
   "source": [
    "norm_scores = (saliency_scores - saliency_scores.min()) / np.ptp(saliency_scores)\n",
    "for t, s in zip(tokens[0].tolist(), norm_scores):\n",
    "    print(f\"Token {t} ‚Üí {s:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb606ef",
   "metadata": {},
   "source": [
    "3) Stretch (optional, 10‚Äì15 min)\n",
    "\n",
    "Task: Create a simple color-coded heatmap over tokens using matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e47ea2d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.bar(range(len(norm_scores)), norm_scores)\n",
    "plt.xticks(range(len(norm_scores)), tokens[0].tolist())\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38604875",
   "metadata": {},
   "source": [
    "Mini-Challenge (‚â§40 min)\n",
    "\n",
    "Task: Apply saliency to 6‚Äì8 IMDB reviews with your BiLSTM sentiment model.\n",
    "\n",
    "Highlight most influential words per review.\n",
    "\n",
    "Save results as a text/plot: review text with colored words.\n",
    "\n",
    "Acceptance Criteria:\n",
    "\n",
    "At least 6 reviews analyzed.\n",
    "\n",
    "Shows tokens + saliency scores.\n",
    "\n",
    "Extract 2 insights (e.g., model overly relies on punctuation, or ignores negation words)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12eb3b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | loss=0.6933\n",
      "Epoch 2 | loss=0.5861\n",
      "br              0.49\n",
      "br              0.31\n",
      "when            0.26\n",
      "i               0.19\n",
      "<unk>           0.15\n",
      "rented          0.14\n",
      "a               0.09\n",
      "thousand        0.11\n",
      "acres           0.09\n",
      "i               0.06\n",
      "thought         0.05\n",
      "i               0.03\n",
      "was             0.04\n",
      "in              0.04\n",
      "for             0.03\n",
      "an              0.03\n",
      "entertaining    0.02\n",
      "king            0.02\n",
      "<unk>           0.01\n",
      "story           0.01\n",
      "and             0.01\n",
      "of              0.01\n",
      "course          0.01\n",
      "michelle        0.01\n",
      "pfeiffer        0.00\n",
      "was             0.00\n",
      "in              0.00\n",
      "it              0.00\n",
      "so              0.00\n",
      "what            0.00\n"
     ]
    }
   ],
   "source": [
    "# ---- Imports ----\n",
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "import numpy as np, re, random\n",
    "from datasets import load_dataset\n",
    "from collections import Counter\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Reproducibility\n",
    "SEED=42\n",
    "torch.manual_seed(SEED); np.random.seed(SEED); random.seed(SEED)\n",
    "\n",
    "# ---- 1. Load IMDB from Hugging Face ----\n",
    "dataset = load_dataset(\"imdb\")\n",
    "\n",
    "# Small subset for speed (CPU friendly)\n",
    "N_TRAIN, N_TEST = 2000, 1000\n",
    "train_subset = dataset[\"train\"].shuffle(seed=SEED).select(range(N_TRAIN))\n",
    "test_subset  = dataset[\"test\"].shuffle(seed=SEED).select(range(N_TEST))\n",
    "\n",
    "# ---- 2. Tokenization + Vocab ----\n",
    "def simple_tokenize(s):\n",
    "    return re.findall(r\"\\b\\w+\\b\", s.lower())\n",
    "\n",
    "counter = Counter()\n",
    "for row in train_subset:\n",
    "    counter.update(simple_tokenize(row[\"text\"]))\n",
    "\n",
    "MAX_VOCAB = 20000\n",
    "PAD, UNK = \"<pad>\", \"<unk>\"\n",
    "itos = [PAD, UNK] + [w for w,_ in counter.most_common(MAX_VOCAB-2)]\n",
    "stoi = {w:i for i,w in enumerate(itos)}\n",
    "\n",
    "def numericalize(tokens): \n",
    "    return [stoi.get(tok, stoi[UNK]) for tok in tokens]\n",
    "\n",
    "MAX_LEN=200\n",
    "\n",
    "class IMDBDataset(Dataset):\n",
    "    def __init__(self, hf_ds):\n",
    "        self.texts = hf_ds[\"text\"]; self.labels = hf_ds[\"label\"]\n",
    "    def __len__(self): return len(self.labels)\n",
    "    def __getitem__(self,i):\n",
    "        return self.labels[i], simple_tokenize(self.texts[i])\n",
    "\n",
    "def collate(batch):\n",
    "    ys,toks = zip(*batch)\n",
    "    ids_list=[numericalize(t)[:MAX_LEN] for t in toks]\n",
    "    lens=torch.tensor([len(x) for x in ids_list],dtype=torch.long)\n",
    "    maxlen=lens.max().item()\n",
    "    PAD_ID=stoi[PAD]\n",
    "    x=torch.full((len(ids_list),maxlen),PAD_ID,dtype=torch.long)\n",
    "    for i,ids in enumerate(ids_list):\n",
    "        x[i,:len(ids)]=torch.tensor(ids)\n",
    "    return x,lens,torch.tensor(ys,dtype=torch.long)\n",
    "\n",
    "train_ds,test_ds=IMDBDataset(train_subset),IMDBDataset(test_subset)\n",
    "train_loader=DataLoader(train_ds,batch_size=32,shuffle=True,collate_fn=collate)\n",
    "test_loader=DataLoader(test_ds,batch_size=32,shuffle=False,collate_fn=collate)\n",
    "\n",
    "# ---- 3. BiLSTM Classifier (your class, adapted) ----\n",
    "class BiLSTMClassifier(nn.Module):\n",
    "    def __init__(self,vocab_size,embed_dim=100,hidden_dim=64,num_classes=2):\n",
    "        super().__init__()\n",
    "        self.embedding=nn.Embedding(vocab_size,embed_dim,padding_idx=stoi[PAD])\n",
    "        self.lstm=nn.LSTM(embed_dim,hidden_dim,batch_first=True,bidirectional=True)\n",
    "        self.fc=nn.Linear(hidden_dim*2,num_classes)\n",
    "    def forward(self,x,lengths):\n",
    "        embeds=self.embedding(x)\n",
    "        packed=nn.utils.rnn.pack_padded_sequence(embeds,lengths.cpu(),batch_first=True,enforce_sorted=False)\n",
    "        _,(h_n,_) = self.lstm(packed)\n",
    "        h_cat=torch.cat((h_n[-2],h_n[-1]),dim=1)\n",
    "        return self.fc(h_cat),embeds\n",
    "\n",
    "device=torch.device(\"cpu\")\n",
    "model=BiLSTMClassifier(len(itos)).to(device)\n",
    "\n",
    "# ---- 4. Quick Train (tiny epochs for demo) ----\n",
    "opt=torch.optim.Adam(model.parameters(),lr=2e-3)\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(2):\n",
    "    model.train(); total_loss=0\n",
    "    for x,lens,y in train_loader:\n",
    "        x,lens,y=x.to(device),lens.to(device),y.to(device)\n",
    "        opt.zero_grad()\n",
    "        logits,_=model(x,lens)\n",
    "        loss=criterion(logits,y)\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(),1.0)\n",
    "        opt.step()\n",
    "        total_loss+=loss.item()*x.size(0)\n",
    "    print(f\"Epoch {epoch+1} | loss={total_loss/len(train_ds):.4f}\")\n",
    "\n",
    "# ---- 5. Saliency on 1 batch of test samples ----\n",
    "model.eval()\n",
    "x, lens, y = next(iter(test_loader))\n",
    "x, lens, y = x.to(device), lens.to(device), y.to(device)\n",
    "\n",
    "# Forward\n",
    "logits, embeds = model(x, lens)\n",
    "preds = logits.argmax(1)\n",
    "\n",
    "# ---- retain grad on non-leaf tensor ----\n",
    "embeds.retain_grad()                    # <-- key line\n",
    "\n",
    "# Use the logit of the predicted class for sample i\n",
    "i = 0\n",
    "score = logits[i, preds[i]]             # scalar\n",
    "model.zero_grad()\n",
    "score.backward()                        # backprop to embeds\n",
    "\n",
    "L = int(lens[i].item())\n",
    "grads = embeds.grad[i, :L]              # [seq_len, emb_dim]\n",
    "saliency = grads.norm(dim=1).detach().cpu().numpy()\n",
    "\n",
    "# Normalize 0‚Äì1 and print tokens + scores\n",
    "sal_norm = (saliency - saliency.min()) / (saliency.max() - saliency.min() + 1e-9)\n",
    "tok_ids = x[i, :L].cpu().tolist()\n",
    "tok_strs = [itos[t] for t in tok_ids]\n",
    "for t, s in zip(tok_strs[:30], sal_norm[:30]):\n",
    "    print(f\"{t:<15} {s:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeec9741",
   "metadata": {},
   "source": [
    "At this stage, the saliency analysis reveals that the BiLSTM isn‚Äôt truly ‚Äúreading sentiment‚Äù yet ‚Äî it‚Äôs mostly reacting to noise. Cleaning the dataset and using pretrained embeddings should shift saliency towards real sentiment-bearing words (e.g., ‚Äúgood,‚Äù ‚Äúboring,‚Äù ‚Äúterrible‚Äù)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70da23d0",
   "metadata": {},
   "source": [
    "Notes / Key Takeaways\n",
    "\n",
    "Gradients on embeddings show token importance.\n",
    "\n",
    "Saliency helps debug ‚Äúwhy‚Äù a prediction was made.\n",
    "\n",
    "Heatmaps expose bias (e.g., ‚Äú!‚Äù = positive, ‚Äúbad‚Äù = always negative).\n",
    "\n",
    "Works best alongside evaluation metrics.\n",
    "\n",
    "Trust requires both accuracy + explainability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8bb0a7",
   "metadata": {},
   "source": [
    "Reflection\n",
    "\n",
    "How can saliency reveal dataset shortcuts the model is learning?\n",
    "\n",
    "Why is explainability critical before deploying models in production?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a58460",
   "metadata": {},
   "source": [
    "How can saliency reveal dataset shortcuts the model is learning?\n",
    "Saliency shows which tokens most influence the prediction. If high scores appear on irrelevant artifacts (e.g., br, <unk>, punctuation), it reveals that the model is relying on dataset shortcuts instead of true sentiment. This helps diagnose spurious correlations and motivates better preprocessing or model design.\n",
    "\n",
    "Why is explainability critical before deploying models in production?\n",
    "Explainability ensures trust and safety: it lets us verify that the model bases decisions on meaningful signals, not noise or bias. Without it, a model could perform well in tests but fail or behave unfairly in real-world settings. By explaining predictions, we gain transparency, detect hidden biases, and build confidence for users and stakeholders."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
